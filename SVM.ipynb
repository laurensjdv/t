{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "from kan import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from dataloaders.dataloader import FCMatrixDataset\n",
    "from utils import balanced_random_split_v2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from fasterkan.fasterkan import FasterKAN\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=99)\n",
    "\n",
    "mrmr_features = np.array([1140, 536, 223, 907, 1449, 499, 1293, 45, 135, 1440, 879, 1384, 1210, 1316, 122, 22, 492, 638, 765, 1027, 1464, 501, 1462, 395, 26, 1079, 70, 425, 1403, 1409, 1318, 886, 1459, 1448, 939, 1163, 547, 10, 413, 676, 131, 216, 942, 1136, 1386, 232, 1455, 1337, 814, 139, 392, 1376, 1382, 471, 656]\n",
    "    )\n",
    "# mrmr_features=None\n",
    "\n",
    "ds = \"data/csv/severe_rds.csv\"\n",
    "# ds = \"data/csv/balanced_sex_classification.csv\"\n",
    "data_dir = \"data/fetched/25751/raw\"\n",
    "udi = \"25751\"\n",
    "dataset = FCMatrixDataset(ds, data_dir, udi, mapping=None, mrmr=mrmr_features)\n",
    "labels = np.genfromtxt(ds)\n",
    "eids = labels[:,0]\n",
    "labels = labels[:,1]\n",
    "eval_metrics = np.zeros((skf.n_splits, 2))\n",
    "\n",
    "# print(dataset[0][0].shape)\n",
    "\n",
    "\n",
    "\n",
    "# total_size = len(ds)\n",
    "# train_size = int(0.8 * total_size)\n",
    "# val_size = int(0.1 * total_size)\n",
    "# test_size = total_size - train_size - val_size\n",
    "\n",
    "# train, val, test = balanced_random_split_v2(ds, [train_size, val_size, test_size], num_classes=2)\n",
    "\n",
    "# train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "[1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0]\n",
      "Fold 1 Val Acc: 0.7500 Test Acc: 0.6667\n",
      "[1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0]\n",
      "[1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0]\n",
      "Fold 2 Val Acc: 0.7500 Test Acc: 0.6250\n",
      "[0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0]\n",
      "Fold 3 Val Acc: 0.7917 Test Acc: 0.9167\n",
      "[1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1]\n",
      "[1 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 1]\n",
      "Fold 4 Val Acc: 0.8333 Test Acc: 0.8333\n",
      "[1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0]\n",
      "[1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1]\n",
      "Fold 5 Val Acc: 0.9583 Test Acc: 0.8750\n",
      "[0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "[0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1]\n",
      "Fold 6 Val Acc: 0.6250 Test Acc: 0.8333\n",
      "[0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1]\n",
      "[0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1]\n",
      "Fold 7 Val Acc: 0.8750 Test Acc: 0.8696\n",
      "[1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "[1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1]\n",
      "Fold 8 Val Acc: 1.0000 Test Acc: 0.8696\n",
      "[0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 0]\n",
      "[1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0]\n",
      "Fold 9 Val Acc: 0.7917 Test Acc: 0.9565\n",
      "[1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0]\n",
      "[1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0]\n",
      "Fold 10 Val Acc: 0.8750 Test Acc: 0.6957\n",
      "              ACC  test_acc\n",
      "Fold_01  0.750000  0.666667\n",
      "Fold_02  0.750000  0.625000\n",
      "Fold_03  0.791667  0.916667\n",
      "Fold_04  0.833333  0.833333\n",
      "Fold_05  0.958333  0.875000\n",
      "Fold_06  0.625000  0.833333\n",
      "Fold_07  0.875000  0.869565\n",
      "Fold_08  1.000000  0.869565\n",
      "Fold_09  0.791667  0.956522\n",
      "Fold_10  0.875000  0.695652\n",
      "Average Accuracy: 0.8250±0.1034\n",
      "Average Accuracy: 0.8250±0.1063\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(41)\n",
    "\n",
    "for n_fold, (train_val, test) in enumerate(skf.split(labels, labels)):\n",
    "    print\n",
    "    clf = svm.SVC(kernel='poly', degree=5, class_weight='balanced')\n",
    "    clf = svm.SVC(kernel='rbf')\n",
    "    # clf = svm.SVC(kernel='linear', C=0.01, gamma=1.0, class_weight='balanced')\n",
    "    # model = KAN([1485, 64, 2])\n",
    "\n",
    "    train_val_dataset, test_dataset = Subset(dataset, train_val), Subset(dataset, test)\n",
    "    train_val_labels = labels[train_val]\n",
    "    train_val_index = np.arange(len(train_val_dataset))\n",
    "\n",
    "    train, val, _, _ = train_test_split(train_val_index, train_val_labels, test_size=0.11, shuffle=True, stratify=train_val_labels)\n",
    "    train_dataset, val_dataset = Subset(train_val_dataset, train), Subset(train_val_dataset, val)\n",
    "    \n",
    "    def seperate_subset(subset):\n",
    "        input = [np.array(subset[i][0]) for i in range(len(subset))]\n",
    "        input = np.array(input)\n",
    "        label = [subset[i][1] for i in range(len(subset))]\n",
    "        label = np.array(label)\n",
    "        return input, label\n",
    "\n",
    "    train_input, train_label = seperate_subset(train_dataset)\n",
    "    val_input, val_label = seperate_subset(val_dataset)\n",
    "    test_input, test_label = seperate_subset(test_dataset)\n",
    "   \n",
    "    clf.fit(train_input, train_label)\n",
    "    val_pred = clf.predict(val_input)\n",
    "    print(val_pred)\n",
    "    print(val_label)\n",
    "    val_acc = np.mean(val_pred == val_label)\n",
    "    test_pred = clf.predict(test_input)\n",
    "    test_acc = np.mean(test_pred == test_label)\n",
    "\n",
    "\n",
    "    # test_sen, test_spe, test_acc, _ = test(test_dataset)\n",
    "\n",
    "    print('Fold %i' % (n_fold + 1), 'Val Acc: %.4f' % val_acc, 'Test Acc: %.4f' % test_acc)\n",
    "    \n",
    "\n",
    "    eval_metrics[n_fold, 0] = val_acc\n",
    "    eval_metrics[n_fold, 1] = test_acc\n",
    "\n",
    "\n",
    "eval_df = pd.DataFrame(eval_metrics)\n",
    "eval_df.columns = ['ACC','test_acc']\n",
    "eval_df.index = ['Fold_%02i' % (i + 1) for i in range(skf.n_splits)]\n",
    "print(eval_df)\n",
    "# print('Average Sensitivity: %.4f±%.4f' % (eval_metrics[:, 0].mean(), eval_metrics[:, 0].std()))\n",
    "# print('Average Specificity: %.4f±%.4f' % (eval_metrics[:, 1].mean(), eval_metrics[:, 1].std()))\n",
    "print('Average Accuracy: %.4f±%.4f' % (eval_metrics[:, 0].mean(), eval_metrics[:, 0].std()))\n",
    "print('Average Accuracy: %.4f±%.4f' % (eval_metrics[:, 0].mean(), eval_metrics[:, 1].std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
